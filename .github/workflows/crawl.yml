name: Run Crawler on Mon, Wed, Fri (with Weekly Full-Reset)

on:
  workflow_dispatch:
  schedule:
    # Incremental crawls: Mon/Wed/Fri at 1 AM Dubai (21:00 UTC prev. day)
    - cron: '0 21 * * 1,3,5'
    # Full-reset crawl: Sunday at 1 AM Dubai (21:00 UTC Saturday)
    - cron: '0 21 * * 6'

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      # ──────────── RAW FEED HASH ────────────
      - name: Calculate raw feed hash
        id: calc_hash
        run: |
          sha256=$(sha256sum google_feed/google_merchant_feed.csv | cut -d' ' -f1)
          echo "current_hash=$sha256" >> $GITHUB_OUTPUT

      - name: Read previous raw hash
        id: read_prev_hash
        run: |
          if [[ -f .github/last_raw_hash.txt ]]; then
            prev_hash=$(cat .github/last_raw_hash.txt)
          else
            prev_hash=""
          fi
          echo "prev_hash=$prev_hash" >> $GITHUB_OUTPUT

      - name: Compare raw hashes
        id: check_hash
        run: |
          if [[ "${{ steps.calc_hash.outputs.current_hash }}" != "${{ steps.read_prev_hash.outputs.prev_hash }}" ]]; then
            echo "feed_changed=true" >> $GITHUB_OUTPUT
          else
            echo "feed_changed=false" >> $GITHUB_OUTPUT
          fi

      - name: Save new raw hash
        if: ${{ steps.check_hash.outputs.feed_changed == 'true' }}
        run: |
          echo "${{ steps.calc_hash.outputs.current_hash }}" > .github/last_raw_hash.txt
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add .github/last_raw_hash.txt
          git commit -m "Update raw feed hash [skip ci]" || echo "No changes to commit"
          git push

      # ──────────── CACHING & SETUP ────────────
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Cache Google Product Taxonomy
        id: cache-taxonomy
        uses: actions/cache@v3
        with:
          path: google_product_taxonomy.txt
          key: google-product-taxonomy-${{ runner.os }}-v1
          restore-keys: |
            google-product-taxonomy-${{ runner.os }}-

      - name: Cache category suggestions CSV
        id: cache-category-suggestions
        uses: actions/cache@v3
        with:
          path: category_suggestions.csv
          key: category-suggestions-${{ runner.os }}-v1
          restore-keys: |
            category-suggestions-${{ runner.os }}-

      - name: Restore cache for seen_products.json
        id: cache-seen-products
        uses: actions/cache@v3
        with:
          path: seen_products.json
          key: seen-products-${{ runner.os }}-v1
          restore-keys: |
            seen-products-${{ runner.os }}-

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create necessary directories
        run: mkdir -p product_urls google_feed meta_feed

      # ──────────── MODE & CRAWL ────────────
      - name: Determine Crawl Mode (Dubai time)
        id: mode
        run: |
          DOW=$(TZ="Asia/Dubai" date +'%u')
          if [[ "$DOW" == "7" ]]; then
            echo "MODE=force" >> $GITHUB_ENV
          else
            echo "MODE=incremental" >> $GITHUB_ENV
          fi

      - name: Run crawler & feed-gen
        if: ${{ steps.check_hash.outputs.feed_changed == 'true' || env.MODE == 'force' }}
        run: |
          if [[ "${{ env.MODE }}" == "force" ]]; then
            echo "▶ Full-reset crawl"
            python crawler.py --force
          else
            echo "▶ Incremental crawl"
            python crawler.py
          fi
          python product_feed_generator.py
          python meta_feed_generator.py

      - name: Save seen_products.json
        if: steps.cache-seen-products.outputs.cache-hit != 'true'
        run: echo "state updated"

      # ──────────── VALIDATION & PREP ────────────
      - name: Download Google product taxonomy
        if: steps.cache-taxonomy.outputs.cache-hit != 'true'
        run: python download_taxonomy.py

      - name: Validate Google product categories
        run: python download_and_validate_full.py
        env:
          FEED_FILE: google_feed/google_merchant_feed.csv

      - name: Prepare input for category_updater
        run: cp google_feed/google_merchant_feed.csv ./google_merchant_feed.csv

      # ──────────── CATEGORY UPDATER ────────────
      - name: Auto-assign Google categories
        run: python category_updater.py

      # ──────────── CATEGORIZED FEED HASH ────────────
      - name: Calculate categorized feed hash
        id: calc_cat_hash
        run: |
          sha256=$(sha256sum google_merchant_feed_updated.csv | cut -d' ' -f1)
          echo "cat_hash=$sha256" >> $GITHUB_OUTPUT

      - name: Read previous categorized hash
        id: read_prev_cat_hash
        run: |
          if [[ -f .github/last_cat_hash.txt ]]; then
            prev_cat=$(cat .github/last_cat_hash.txt)
          else
            prev_cat=""
          fi
          echo "prev_cat_hash=$prev_cat" >> $GITHUB_OUTPUT

      - name: Compare categorized hashes
        id: check_cat_hash
        run: |
          if [[ "${{ steps.calc_cat_hash.outputs.cat_hash }}" != "${{ steps.read_prev_cat_hash.outputs.prev_cat_hash }}" ]]; then
            echo "cat_changed=true" >> $GITHUB_OUTPUT
          else
            echo "cat_changed=false" >> $GITHUB_OUTPUT
          fi

      # ──────────── PUBLISH & COMMIT ON CHANGE ────────────
      - name: Move & publish updated feed
        if: steps.check_cat_hash.outputs.cat_changed == 'true'
        run: |
          mkdir -p google_feed
          mv google_merchant_feed_updated.csv google_feed/google_merchant_feed_updated.csv
          python sheets_publisher.py \
            --credentials "${{ secrets.GOOGLE_SHEETS_CREDENTIALS }}" \
            --spreadsheet-id "1aNtP8UJyy8sDYf3tPpCAZt-zMMHwofjpyEqrN9b1bJI" \
            --worksheet-name "google_merchant_feed" \
            --feed-file "google_feed/google_merchant_feed_updated.csv"
          echo "${{ steps.calc_cat_hash.outputs.cat_hash }}" > .github/last_cat_hash.txt
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add .github/last_cat_hash.txt google_feed/google_merchant_feed_updated.csv
          git commit -m "Publish updated categorized feed [skip ci]" || echo "No changes to commit"
          git push

      - name: Skip publish if no category changes
        if: steps.check_cat_hash.outputs.cat_changed == 'false'
        run: echo "✅ No category changes; skipping publish."
