# .github/workflows/crawl.yml

name: Run Crawler on Mon, Wed, Fri (with Weekly Full-Reset)

on:
  workflow_dispatch:
  schedule:
    # Incremental crawls: Mon/Wed/Fri at 1 AM Dubai (21:00 UTC prev. day)
    - cron: '0 21 * * 1,3,5'
    # Full-reset crawl: Sunday at 1 AM Dubai (21:00 UTC Saturday)
    - cron: '0 21 * * 6'

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CACHING & SETUP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Cache Google Product Taxonomy
        id: cache-taxonomy
        uses: actions/cache@v3
        with:
          path: google_product_taxonomy.txt
          key: google-product-taxonomy-${{ runner.os }}-v1
          restore-keys: |
            google-product-taxonomy-${{ runner.os }}-

      - name: Cache category suggestions CSV
        id: cache-category-suggestions
        uses: actions/cache@v3
        with:
          path: category_suggestions.csv
          key: category-suggestions-${{ runner.os }}-v1
          restore-keys: |
            category-suggestions-${{ runner.os }}-

      - name: Restore cache for seen_products.json
        id: cache-seen-products
        uses: actions/cache@v3
        with:
          path: seen_products.json
          key: seen-products-${{ runner.os }}-v1
          restore-keys: |
            seen-products-${{ runner.os }}-

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create necessary directories
        run: mkdir -p product_urls google_feed meta_feed .github

      # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ MODE & CRAWL (ALWAYS RUN) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Determine Crawl Mode (Dubai time)
        id: mode
        run: |
          DOW=$(TZ="Asia/Dubai" date +'%u')
          if [[ "$DOW" == "7" ]]; then
            echo "MODE=force" >> $GITHUB_ENV
            echo "üîÑ Running FULL-RESET crawl (Sunday in Dubai)"
          else
            echo "MODE=incremental" >> $GITHUB_ENV
            echo "üîÑ Running INCREMENTAL crawl"
          fi

      # CRITICAL FIX: Always run crawler to find new products
      - name: Run crawler & feed generators
        run: |
          echo "üöÄ Starting crawler and feed generation..."
          if [[ "${{ env.MODE }}" == "force" ]]; then
            echo "‚ñ∂ Full-reset crawl (purging state files)"
            python crawler.py --force
          else
            echo "‚ñ∂ Incremental crawl (preserving existing data)"
            python crawler.py
          fi
          
          echo "‚ñ∂ Generating product feeds"
          python product_feed_generator.py
          
          echo "‚ñ∂ Generating Meta/Facebook feeds"
          python meta_feed_generator.py

      # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ VALIDATION & PREP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Download Google product taxonomy
        if: steps.cache-taxonomy.outputs.cache-hit != 'true'
        run: python download_taxonomy.py

      - name: Validate Google product categories
        run: python download_and_validate_full.py
        env:
          FEED_FILE: google_feed/google_merchant_feed.csv

      # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CATEGORY UPDATER ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Auto-assign Google categories with enhanced analysis
        run: |
          if [[ -f google_feed/google_merchant_feed.csv ]]; then
            cp google_feed/google_merchant_feed.csv ./google_merchant_feed.csv
            python category_updater.py
          else
            echo "‚ùå google_merchant_feed.csv not found!"
            exit 1
          fi

      # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ FEED HASH COMPARISON ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Calculate new feed hash
        id: calc_new_hash
        run: |
          if [[ -f google_merchant_feed_updated.csv ]]; then
            sha256=$(sha256sum google_merchant_feed_updated.csv | cut -d' ' -f1)
            echo "‚úÖ Updated feed hash: $sha256"
          else
            sha256=""
            echo "‚ö†Ô∏è No updated feed found"
          fi
          echo "new_hash=$sha256" >> $GITHUB_OUTPUT

      - name: Read previous feed hash
        id: read_prev_hash
        run: |
          if [[ -f .github/last_feed_hash.txt ]]; then
            prev_hash=$(cat .github/last_feed_hash.txt)
            echo "üìÑ Previous hash: $prev_hash"
          else
            prev_hash=""
            echo "üìÑ No previous hash found"
          fi
          echo "prev_hash=$prev_hash" >> $GITHUB_OUTPUT

      - name: Compare feed hashes for changes
        id: check_changes
        run: |
          new_hash="${{ steps.calc_new_hash.outputs.new_hash }}"
          prev_hash="${{ steps.read_prev_hash.outputs.prev_hash }}"
          
          if [[ -n "$new_hash" && "$new_hash" != "$prev_hash" ]]; then
            echo "feed_changed=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Feed changes detected - will publish to Google Sheets"
          else
            echo "feed_changed=false" >> $GITHUB_OUTPUT
            echo "‚ÑπÔ∏è No feed changes detected - skipping publish"
          fi

      # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ PUBLISH & COMMIT ON CHANGE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      - name: Publish updated feed to Google Sheets
        if: steps.check_changes.outputs.feed_changed == 'true'
        env:
          GOOGLE_SHEETS_CREDENTIALS: ${{ secrets.GOOGLE_SHEETS_CREDENTIALS }}
          SPREADSHEET_ID: "1aNtP8UJyy8sDYf3tPpCAZt-zMMHwofjpyEqrN9b1bJI"
          WORKSHEET_NAME: "google_merchant_feed"
          FEED_FILE: "google_feed/google_merchant_feed_updated.csv"
        run: |
          echo "‚ñ∂ Publishing updated feed to Google Sheets"
          mkdir -p google_feed
          if [[ -f google_merchant_feed_updated.csv ]]; then
            mv google_merchant_feed_updated.csv google_feed/google_merchant_feed_updated.csv
          fi
          python sheets_publisher.py

      - name: Commit and push changes
        if: steps.check_changes.outputs.feed_changed == 'true'
        run: |
          echo "‚ñ∂ Committing updated feeds to repository"
          echo "${{ steps.calc_new_hash.outputs.new_hash }}" > .github/last_feed_hash.txt
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add -A
          git commit -m "üöÄ Updated product feeds with enhanced categorization - $(date '+%Y-%m-%d %H:%M')" || echo "No changes to commit"
          git push

      - name: Summary of crawler run
        run: |
          echo "========================================"
          echo "üìä CRAWLER RUN SUMMARY"
          echo "========================================"
          echo "Mode: ${{ env.MODE }}"
          echo "Feed changed: ${{ steps.check_changes.outputs.feed_changed }}"
          echo "Time: $(date)"
          
          if [[ -f product_urls/product_links.csv ]]; then
            product_count=$(tail -n +2 product_urls/product_links.csv 2>/dev/null | wc -l || echo "0")
            echo "Products discovered: $product_count"
          else
            echo "Products discovered: 0 (file not found)"
          fi
          
          if [[ -f google_feed/google_merchant_feed_updated.csv ]]; then
            feed_count=$(tail -n +2 google_feed/google_merchant_feed_updated.csv 2>/dev/null | wc -l || echo "0")
            echo "Products in final feed: $feed_count"
          elif [[ -f google_feed/google_merchant_feed.csv ]]; then
            feed_count=$(tail -n +2 google_feed/google_merchant_feed.csv 2>/dev/null | wc -l || echo "0")
            echo "Products in feed: $feed_count"
          else
            echo "Products in feed: 0 (file not found)"
          fi
          echo "========================================"

      - name: Show recent product URLs (for debugging)
        run: |
          echo "üîç RECENT PRODUCT URLs (Last 10):"
          if [[ -f product_urls/product_links.csv ]]; then
            tail -10 product_urls/product_links.csv || echo "Error reading file"
          else
            echo "No product URLs file found"
          fi
          
          echo ""
          echo "üéØ CATEGORIZATION RESULTS:"
          if [[ -f categorization_review_report.csv ]]; then
            echo "Review report created: categorization_review_report.csv"
          fi
